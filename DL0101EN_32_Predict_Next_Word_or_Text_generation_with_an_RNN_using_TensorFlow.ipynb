{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL0101EN-32-Predict Next Word or Text generation with an RNN using TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZecB2FRc-JS"
      },
      "source": [
        "import os\r\n",
        "import time\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1eyFTdvdHxR"
      },
      "source": [
        "### Data Collection:\r\n",
        "\r\n",
        "* [Shakespeare dataset](https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt)\r\n",
        "* [Shakespeare dataset](https://raw.githubusercontent.com/reddyprasade/Deep-Learning-with-Tensorflow-2.x/main/Data/input.txt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ2HoEq-dG-k",
        "outputId": "f7b20a5d-179f-4835-9f95-2a55f4d5c0be"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjBuiUOndvQB",
        "outputId": "1b77bef9-f8aa-419d-cd3b-97fee27e897d"
      },
      "source": [
        "# Read the text file data\r\n",
        "text = open(path_to_file,'rb').read().decode(encoding='utf-8')\r\n",
        "print(\"Length of text:{} charaters\".format(len(text)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text:1115394 charaters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSyq9LszeTvy",
        "outputId": "34bd26b3-4ee1-4b9b-e4d1-3582cca71a7c"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSLObnuKeoRI",
        "outputId": "74561c3d-baf4-4a44-b820-797f6cf2e5a6"
      },
      "source": [
        "vocab = sorted(set(text))\r\n",
        "print(\"{} Unique Characters From Text Data\".format(len(vocab)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 Unique Characters From Text Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljkrmmJqfNoZ"
      },
      "source": [
        "example_text = ['abcdefg','xyz']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIKwOsM4fl4h",
        "outputId": "e89fc0d6-e5df-415e-d84d-5cd92be5cc19"
      },
      "source": [
        "chars = tf.strings.unicode_split(example_text,input_encoding='UTF-8')\r\n",
        "chars"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLljHxHffzr0"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WfODi8ogLUY",
        "outputId": "7ffdc1d0-5635-4f9b-9d67-c24ece64f83c"
      },
      "source": [
        "ids_from_chars"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.preprocessing.string_lookup.StringLookup at 0x7f9c41295908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h24jYa-4gMgZ",
        "outputId": "ffcfc16f-3311-4bb6-fbc2-9abc1ed8ef51"
      },
      "source": [
        "ids = ids_from_chars(chars)\r\n",
        "ids"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[41, 42, 43, 44, 45, 46, 47], [64, 65, 66]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR_ZXc3sgT6x"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\r\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZoRi_QVgaF7",
        "outputId": "5273ad91-7cc9-411f-a82e-71eab3d89a64"
      },
      "source": [
        "chars = chars_from_ids(ids)\r\n",
        "chars"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ngspfT7gfzM",
        "outputId": "1a97158b-e55b-4cc4-d2f8-36b143a302f5"
      },
      "source": [
        "tf.strings.reduce_join(chars,axis=-1).numpy()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDLB-ZKPgsaO"
      },
      "source": [
        "def text_from_ids(ids):\r\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YavftYvXgz3v",
        "outputId": "a7c55914-d749-405f-d251-af739f6f3ffc"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text,'UTF-8'))\r\n",
        "all_ids"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([20, 49, 58, ..., 47, 10,  2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaNEduXvhDjM"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTKFyYdNhMM2",
        "outputId": "1158999c-e3aa-4988-a7a3-c1018950feeb"
      },
      "source": [
        "for ids in ids_dataset.take(10):\r\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COk5N5LGlHAD",
        "outputId": "e3436fbe-d65a-4ebb-f045-f41bfe79d85c"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zN8x_mUhauq"
      },
      "source": [
        "seq_length = 100\r\n",
        "example_per_epoch =len(text)//(seq_length+1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znJ6tH9-hzHl",
        "outputId": "9124f693-b511-4e67-f68e-1ca4af8ffe2b"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1,drop_remainder=True)\r\n",
        "\r\n",
        "for seq in sequences.take(1):\r\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OJOGuDaiNwI",
        "outputId": "858e65ca-d3b7-4823-e96a-252fb7db71de"
      },
      "source": [
        "for seq in sequences.take(5):\r\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y261JLveicAQ"
      },
      "source": [
        "def split_input_target(sequences):\r\n",
        "  input_text = sequences[:-1]\r\n",
        "  target_text = sequences[1:]\r\n",
        "  return input_text,target_text\r\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrJjcWTPjTYo",
        "outputId": "f1699228-b5ce-43d0-d0c4-05aa0897c843"
      },
      "source": [
        "split_input_target(list('Python'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['P', 'y', 't', 'h', 'o'], ['y', 't', 'h', 'o', 'n'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azpci1u-jZzB"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmKYZTyBj7eF",
        "outputId": "bf130837-503a-47e2-acb2-1ea56608b0b0"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\r\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\r\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QM_0JUnkKLy"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "BUFFER_SIZE = 10000\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zykuoutykr9G"
      },
      "source": [
        "dataset = (dataset\r\n",
        "           .shuffle(BUFFER_SIZE)\r\n",
        "           .batch(BATCH_SIZE,drop_remainder=True)\r\n",
        "           .prefetch(tf.data.experimental.AUTOTUNE)\r\n",
        "           )"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4juYtjWSlDrO",
        "outputId": "ccd49753-bc7b-4ab7-e532-3b15c8995626"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwoZ3h61lEqJ"
      },
      "source": [
        "vocab_size = len(vocab)\r\n",
        "embedding_dim = 256\r\n",
        "rnn_units = 1024"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPro-4SjlsI3"
      },
      "source": [
        "class MyModel(tf.keras.Model):\r\n",
        "  \r\n",
        "  \r\n",
        "  def __init__(self,vocab_size,embedding_dim,rnn_units):\r\n",
        "    super().__init__(self)\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\r\n",
        "                                   return_sequences=True,\r\n",
        "                                   return_state=True)\r\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "  def call(self,inputs,states=None,return_state=False,training=False):\r\n",
        "    x = inputs\r\n",
        "    x = self.embedding(x,training=training)\r\n",
        "    if states is None:\r\n",
        "      states = self.gru.get_initial_state(x)\r\n",
        "    x,states = self.gru(x, initial_state=states,training=training)\r\n",
        "    x = self.dense(x,training=training)\r\n",
        "    if return_state:\r\n",
        "      return x,states\r\n",
        "    else:\r\n",
        "      return x"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYVORhz8msTx"
      },
      "source": [
        "model = MyModel(vocab_size= len(ids_from_chars.get_vocabulary()),\r\n",
        "                embedding_dim=embedding_dim,\r\n",
        "                rnn_units = rnn_units\r\n",
        "    \r\n",
        ")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qcwTzFZoqf3",
        "outputId": "a1e47f01-09ac-4fc9-fa1f-bd99baf6e92a"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\r\n",
        "  example_batch_predictions  = model(input_example_batch)\r\n",
        "  print(example_batch_predictions.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 67)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPV160Z0pnDq"
      },
      "source": [
        "* **64** is my batch_size\r\n",
        "* **100** is my sequence_length\r\n",
        "* **67** is my vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8DAJ6MBpKv0",
        "outputId": "7ebeae32-fbd3-4529-89f6-4f9d4e9a402e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      multiple                  17152     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  68675     \n",
            "=================================================================\n",
            "Total params: 4,024,131\n",
            "Trainable params: 4,024,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFR7Bxgcp3nk"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\r\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-7J7kAdqBMI",
        "outputId": "060cbc18-2787-4d15-e1d2-d3fdf489f2de"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14, 44, 16,  7, 13, 13, 59, 40, 41, 48,  4,  8, 14, 24, 56, 37,  2,\n",
              "       64, 13, 63,  0, 25, 18, 21, 56,  8, 39, 23, 21, 37, 50,  6, 38, 32,\n",
              "       33, 53, 53, 54, 35, 45, 61, 28, 15, 20,  0,  7, 30, 55,  4, 45, 11,\n",
              "       47, 52, 57,  2, 27,  8, 30, 24, 47, 46, 47, 32, 21, 24,  8, 42,  2,\n",
              "        9, 51, 52, 40, 54, 15, 44, 21, 14,  9,  7, 13, 63, 47, 36, 22, 34,\n",
              "        8, 29, 24, 41, 61,  7,  3, 59, 28, 17, 59, 26, 17, 36, 33])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sgreZLMqFiz",
        "outputId": "a1962bd0-99a1-4d23-9365-636c2c3cf042"
      },
      "source": [
        "print(\"Input \\n\",text_from_ids(input_example_batch[0].numpy()))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input \n",
            " tf.Tensor(b'II:\\nBarkloughly castle call they this at hand?\\n\\nDUKE OF AUMERLE:\\nYea, my lord. How brooks your grace', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCR8lDYpqO0S",
        "outputId": "a3fc0867-2f20-4ea2-f717-dac3eddfaf89"
      },
      "source": [
        "print(\"Next Char Predication:\\n\",text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Next Char Predication:\n",
            " b\"?dB';;sZah!,?JpW\\nx;wKDGp,YIGWj&XRSmmnUeuNAF'Po!e3glq\\nM,PJgfgRGJ,b\\n-klZnAdG?-';wgVHT,OJau' sNCsLCVS\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri4GlFt5qeOb"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq-Eso6-qw2c"
      },
      "source": [
        "example_batch_loss  = loss(target_example_batch,example_batch_predications)\r\n",
        "mean_loss = example_batch_loss.numpy().mean()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US1Y-0Nfq-U1",
        "outputId": "b8ef749f-5d03-45b5-a954-b69771c0bd11"
      },
      "source": [
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\r\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 67)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.205204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmxbkeLWq_0W",
        "outputId": "1f3551bf-18ad-44c8-e864-4fc955111c75"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.03427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k68G7FMrF_w"
      },
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYsH4bwYrPpv"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_prefix,\r\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-eR16f-roRB"
      },
      "source": [
        "EPOCHS = 5"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMj8hqnVrsRC",
        "outputId": "44273cb8-9565-4d29-f463-6e7a6aa22666"
      },
      "source": [
        "history = model.fit(dataset,epochs=EPOCHS,\r\n",
        "                    callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 30/172 [====>.........................] - ETA: 12:28 - loss: 2.7559"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0f94coEtSsd"
      },
      "source": [
        "### Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "564_H2x8r16Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}