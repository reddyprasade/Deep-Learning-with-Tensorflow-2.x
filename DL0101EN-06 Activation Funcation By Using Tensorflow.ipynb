{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-12-17T10:43:48.998Z",
          "iopub.execute_input": "2020-12-17T10:43:49.006Z",
          "shell.execute_reply": "2020-12-17T10:43:51.984Z",
          "iopub.status.idle": "2020-12-17T10:43:51.991Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exponential Linear Unit (ELU):\n",
        "\n",
        "The exponential linear unit (ELU) with alpha > 0 is: x if x > 0 and alpha * (exp(x) - 1) if x < 0 The ELU hyperparameter alpha controls the value to which an ELU saturates for negative net inputs. ELUs diminish the vanishing gradient effect.\n",
        "\n",
        "#### **Arguments**\n",
        "* `x`\tInput tensor.\n",
        "* `alpha`\tA scalar, slope of negative section. alpha controls the value to which an ELU saturates for negative net inputs."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='elu',\n",
        "         input_shape=(28, 28, 1)))"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-12-17T10:44:04.132Z",
          "iopub.execute_input": "2020-12-17T10:44:04.137Z",
          "iopub.status.idle": "2020-12-17T10:44:07.456Z",
          "shell.execute_reply": "2020-12-17T10:44:07.467Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-12-17T10:44:22.150Z",
          "iopub.execute_input": "2020-12-17T10:44:22.158Z",
          "iopub.status.idle": "2020-12-17T10:44:22.169Z",
          "shell.execute_reply": "2020-12-17T10:44:22.178Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='elu'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-12-17T10:44:41.200Z",
          "iopub.execute_input": "2020-12-17T10:44:41.210Z",
          "iopub.status.idle": "2020-12-17T10:44:41.225Z",
          "shell.execute_reply": "2020-12-17T10:44:41.234Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Returns\n",
        "The exponential linear unit (ELU) activation function: x if x > 0 and alpha * (exp(x) - 1) if x < 0."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "argv": [
        "python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.27.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}